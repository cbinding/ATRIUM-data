{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# load required dependencies\n",
    "%pip install --upgrade pip\n",
    "%pip install -r \"./requirements.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorisation and parsing of GoTriple keyword values\n",
    "\n",
    "This notebook demonstrates categorization of GoTriple keywords by comparing them to predefined known patterns. It also demonstrates the parsing of identification codes and/or labels (where possible). A keyword analysis was undertaken on GoTriple resources by Net7 for the ATRIUM project, the results were uploaded to a Google Sheet for review and further processing. It was observed that the 'KEYWORD' column sometimes contains values that are not free-text words or phrases, but instead are codes (or codes combined with terms) representing concepts from an external scheme (e.g. DDC, AGROVOC, MeSH). Some observed examples are listed below\n",
    "\n",
    "### CNRS CLASSIFICATION\n",
    "The origin of these codes is \"Centre national de la recherche scientifique (CNRS) France\"\n",
    "Examples from the keywords analysis spreadsheet:\n",
    "* \"[SHS.ARCHEO] Humanities and Social Sciences/Archaeology and Prehistory\"\n",
    "* \"[SHS.SCIPO] Humanities and Social Sciences/Political science\" \n",
    "\n",
    "### VLB (Verzeichnis lieferbarer Bücher) genre\n",
    "Examples from the keywords analysis spreadsheet:\n",
    "* \"(VLB-WN)2115: TB/Belletristik/Anthologien\"\n",
    "* \"(VLB-WN)2580: Taschenbuch / Kunst\"\n",
    "\n",
    "### BISAC subject headings\n",
    "See [https://www.bisg.org/complete-bisac-subject-headings-list](https://www.bisg.org/complete-bisac-subject-headings-list)\n",
    "eg \"(BISAC Subject Heading)FIC031000: FICTION / Thrillers / General\" - see https://www.bisg.org/fiction - listed here\n",
    "\n",
    "### Mixed indexing\n",
    "Example of a GoTriple record with a mixture of keyword indexing: [https://www.gotriple.eu/documents/dnb_1274564107](https://www.gotriple.eu/documents/dnb_127456410)\n",
    "The keywords section contains English, German, VLB, BISAC (code), BISAC (code & labels), semicolon delimited values, prefixed values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item count = 65500\n",
      "categories:\n",
      "\"(BLANK)\" : 60899\n",
      "\"AGROVOC\" : 111\n",
      "\"ALPHA\" : 23\n",
      "\"BIC\" : 14\n",
      "\"BISAC\" : 243\n",
      "\"BK\" : 124\n",
      "\"CNRS\" : 250\n",
      "\"DDC\" : 492\n",
      "\"DK\" : 23\n",
      "\"HAL\" : 97\n",
      "\"JEL\" : 525\n",
      "\"MESH\" : 69\n",
      "\"NUMBER\" : 295\n",
      "\"SSD\" : 52\n",
      "\"STW\" : 42\n",
      "\"TEMPORAL\" : 98\n",
      "\"UNKNOWN2\" : 20\n",
      "\"UNKNOWN3\" : 844\n",
      "\"UNKNOWN4\" : 393\n",
      "\"UNKNOWN5\" : 351\n",
      "\"UNKNOWN6\" : 19\n",
      "\"VLB\" : 516\n"
     ]
    }
   ],
   "source": [
    "# import required library modules\n",
    "import json\n",
    "import os.path\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "\n",
    "def normalize_whitespace(s: str=\"\") -> str:\n",
    "    return \" \".join(s.strip().split()) \n",
    "    \n",
    "\n",
    "def get_gotriple_keywords_analysis_data() -> []:\n",
    "    # read first tab of GoTriple Keywords analysis Google spreadsheet to local CSV file\n",
    "    # subsequently use as cache, only do remote request if the local file is not present\n",
    "    # returns array of dict [{KEYWORD, COUNT}, {KEYWORD, COUNT}, ..]\n",
    "    REMOTE_CSV = \"https://docs.google.com/spreadsheets/d/1rI_BrE6BcyWCkipaKqTZ5bQJXcLwFMMkLpLMu1s7gKg/export?format=csv\"\n",
    "    LOCAL_CSV = \"./data/gotriple-keywords-analysis.csv\"\n",
    "    if not os.path.exists(LOCAL_CSV):    \n",
    "        df = pd.read_csv(REMOTE_CSV, skip_blank_lines=True, index_col=0)\n",
    "        df.to_csv(LOCAL_CSV)      \n",
    "    else: \n",
    "        df = pd.read_csv(LOCAL_CSV, skip_blank_lines=True, index_col=0)\n",
    "\n",
    "     # set any NaN values to blank string\n",
    "    df.fillna(\"\", inplace=True)\n",
    "    return df.to_dict(orient=\"records\") # TODO: need to avoid outputting the 'unnamed' index field..\n",
    "    \n",
    "\n",
    "def categorize_by_regex(items: list=[], pattern: str=\"^.*$\", category: str=\"\"):\n",
    "    reg = re.compile(pattern)\n",
    "    \n",
    "    # try matching the given pattern against all currently uncategorised items\n",
    "    uncategorized_items = filter(lambda item: item.get(category, \"\") == \"\", items)\n",
    "    for item in uncategorized_items:\n",
    "        keyword = normalize_whitespace(str(item.get(\"KEYWORD\", \"\")))\n",
    "        if(keyword != \"\"):\n",
    "            match = reg.fullmatch(keyword)\n",
    "            # if matched, supplement item with additional properties\n",
    "            if match is not None:\n",
    "                item[\"category\"] = category\n",
    "                groups = match.groupdict()            \n",
    "                item[\"code\"] = groups.get(\"code\", \"\")\n",
    "                item[\"subcode\"] = groups.get(\"subcode\", \"\")\n",
    "                item[\"label\"] = groups.get(\"label\", \"\")\n",
    "\n",
    "\n",
    "def categorize(items: list=[]):\n",
    "    # try matching keywords against each regular expression pattern. \n",
    "    # Patterns contain named groups for parsing of codes and labels\n",
    "    categorize_by_regex(items, r'^http://aims\\.fao\\.org/aos/agrovoc/(?P<code>c_\\d+)$', \"AGROVOC\") # 111 categorized\n",
    "    categorize_by_regex(items, r'^\\(BIC subject category\\)(?P<code>[A-Z]+)(?::\\s)?(?P<label>.*)$', \"BIC\") # 14 categorized\n",
    "    categorize_by_regex(items, r'^\\(BISAC Subject Heading\\)(?P<code>[A-Z]+[0-9]+)(?::\\s)?(?P<label>.*)$', \"BISAC\") # 243 categorized\n",
    "    categorize_by_regex(items, r'^(?P<code>\\d{2}\\.\\d{2})\\s(?P<label>[A-ZÄÖÜß].*)$', \"BK\") # 124 categorized\n",
    "    categorize_by_regex(items, r'^ddc:(?P<code>[\\d.]+)$', \"DDC\") # 195 categorized\n",
    "    categorize_by_regex(items, r'^ddc:(?P<code>[\\d]+\\.[\\d]+)$', \"DDC\") #  21 categorized\n",
    "    categorize_by_regex(items, r'^(?P<code>[\\d]{3}(?:\\.[\\d]+)?)\\s(?P<label>[A-ZÄÖÜß].+)$', \"DDC\") # 214 categorized\n",
    "    categorize_by_regex(items, r'^\\(DDC-Sachgruppen der Deutschen Nationalbibliografie\\)(?P<code>[\\d.]+)$', \"DDC\") # 9 categorized\n",
    "    categorize_by_regex(items, r'^info:eu-repo/classification/ddc/(?P<code>[\\d.]+).*$', \"DDC\") # 74 categorized\n",
    "    categorize_by_regex(items, r'^/dk/atira/pure/core/keywords/(?P<label>[^0-9]+)$', \"DK\") # 24 categorized\n",
    "    categorize_by_regex(items, r'^/dk/atira/pure/core/keywords/(?P<code>[0-9]+)$', \"DK\") # 24 categorized\n",
    "    categorize_by_regex(items, r'^\\[(?P<code>[A-Z\\-]{3,}(\\.[A-Z\\-]+)+)\\](?P<label>.*)$', \"HAL\") # 334 categorized\n",
    "    categorize_by_regex(items, r'^jel:(?P<code>[A-Z]\\d+)$', \"JEL\") # 329 categorized\n",
    "    categorize_by_regex(items, r'^JEL:\\s(?P<code>[^\\s]+)\\s-\\s(?P<label>.*)$', \"JEL\") # 196 categorized\n",
    "    #categorize_by_regex(items, r'^JEL:\\s(?P<code>.*)$', \"JEL3\") # 196 categorized\n",
    "    categorize_by_regex(items, r'^MESH:\\s(?P<label>[A-Z].+)$', \"MESH\") # 69 categorized\n",
    "    categorize_by_regex(items, r'^Settore\\s(?P<code>[^\\s]+)\\s-\\s(?P<label>[A-Z].*)$', \"SSD\") # 52 categorized\n",
    "    categorize_by_regex(items, r'^\\(stw\\)(?P<label>[A-ZÄÖÜß].+)$', \"STW\") # 42 categorized\n",
    "    categorize_by_regex(items, r'^Temporal coverage:(?P<label>.+)$', \"TEMPORAL\") # 98 categorized\n",
    "    categorize_by_regex(items, r'^\\((?P<code>VLB-[A-ZÄÖÜß]+)\\)(?P<subcode>[^:\\s]+):\\s(?P<label>.*$)', \"VLB\") # 516 categorized   \n",
    "    categorize_by_regex(items, r'^\\[(?P<code>[A-Z]+-?[A-Z+](?:\\.[[A-Z]+-?[A-Z+])*)\\](?P<label>.*)$', \"CNRS\") # 250 categorized\n",
    "    categorize_by_regex(items, r'^\\(Produktform\\)(?P<label>.*)$', \"UNKNOWN2\") # 20 categorized\n",
    "    categorize_by_regex(items, r'^(?P<code>[A-Z]+[0-9.]+)$', \"UNKNOWN3\") # 844 categorized\n",
    "    categorize_by_regex(items, r'^(?P<code>[A-Z]+[0-9]+)\\s(?P<label>.*)$', \"UNKNOWN4\") # 393 categorized\n",
    "    categorize_by_regex(items, r'^(?P<code>[A-Z]+[0-9.]+-[\\d\\.]+)$', \"UNKNOWN5\") # 351 categorized\n",
    "    categorize_by_regex(items, r'^(?P<code>\\d+)$', \"NUMBER\") # 295 categorized\n",
    "    categorize_by_regex(items, r'^(?P<code>[A-Z])$', \"ALPHA\") # 23 categorized\n",
    "    categorize_by_regex(items, r'^(?:Exact|Close)\\sMatch:\\s(?P<label>.+)$', \"UNKNOWN6\") # 19 categorized\n",
    "    #categorize_by_regex(items, r'^(?P<code>[A-Z0-9]+)$', \"ALPHANUM\") # \n",
    "\n",
    "\n",
    "def summarize(items):\n",
    "    # summarize count of items per category\n",
    "    summary = {}\n",
    "    # calculate counts by category\n",
    "    values = list(map(lambda i: i.get(\"category\", \"(BLANK)\"), items))\n",
    "    counts = list(Counter(values).items()) \n",
    "    counts.sort(key=lambda t: t[0])\n",
    "\n",
    "    # display the calculated counts\n",
    "    print(f\"item count = {len(items)}\") # expected = 65,500\n",
    "    print(\"categories:\")\n",
    "    for category, count in counts:\n",
    "        print(f\"\\\"{category}\\\" : {count}\")\n",
    " \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # get the input data\n",
    "    items = get_gotriple_keywords_analysis_data()\n",
    "\n",
    "    # process the input data\n",
    "    categorize(items)\n",
    "    summarize(items)\n",
    "\n",
    "    # write results to a JSON file\n",
    "    with open(\"./data/gotriple-keywords-categorize-results.json\", \"w\") as out_file:\n",
    "        json.dump(items, out_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
